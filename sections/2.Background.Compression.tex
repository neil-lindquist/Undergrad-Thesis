%TODO General information
Numerous compression strategies were considered for this project.
Figure~\ref{fig:comp-overview} lists the compressions tried for each main data structure.
Note that most compression methods were only used with one or two of the data types, even if able to be reasonably used within the constraints of additional data.

\input{"figures/2.Background/Compression/Strategies Overview.tex"}

\subsubsection{Restrictions on Compression Strategies}
%TODO compression restrictions
The restrictions on usable compression strategies primarily come from the data access requirements described in Section~\ref{sec:bg-da}.
These requirements were that matrix rows need to be readable in both a forward and backwards iteration, the diagonal for a given row must be accessible, and the vectors have both random read access and random, immediate write access.
Due to the highly regular nature of the particular matrix used and the existence of solvers specially optimized for solving this type of problem, the requirement that all compression techniques are able to handle any sparse matrix was added to increase the usefulness of this work~\cite{Saad:2003:IterativeMethods}.
Although, an exception was made to the requirement to handle general matrices for the 1-bit Compression described in Section~\ref{sec:bg-comp-1bit} as that compression method is designed to provide an upper bound for improvements from compressing matrix values.

Note that some cleverness can be used to work around some restrictions.
By compressing the data in small blocks, sequential compression strategies can be used while retaining effectively random access reads and writes~\cite{Lindstrom:2014:zfp}.
Then, at most, the individual block needs to be decompressed or recompressed for a single read or write.
Similarly, a sequential compression method can be used on the matrix information by compressing the data twice, once for forward iteration and once for backwards iteration.


%TODO figure out best order to discussion compressions

\subsubsection{Single and Mixed Precision Floating Point Numbers}
%TODO single & mixed proc

\subsubsection{1 bit Compression}
\label{sec:bg-comp-1bit}
%TODO 1 bit compression

\subsubsection{Squeeze (SZ) Compression}
%TODO review wording of "curve", probably need to use "predictor" or something
Squeeze (SZ) compression is a group of compression strategies based on using curve fitting and can be used for both integers and floating point values.
The compression strategy referred to as SZ compression in this paper deviates from the original description by using a generalization of the core approach of the original implementation of SZ compression~\cite{Di:2016:SZ}.
SZ compression allows for string bounds to be placed on the compression error.

The compressed data is stored in two arrays, one storing the curve each value is compressed with and the other storing values that could not be fit by any curve.
To compress each value, the error between the prediction made by each curve is compared.
If the smallest error is within the user supplied tolerance, the associated curve is stored.
Otherwise, the value is appended to the list of uncompressed values and the curve is stored as uncompressed.
Because only the compressed value is available at decompression time, those values are used during compression time to compute the value produced by each curve.
This allow error requirements to be meet.
The compression rate is
\[
	\frac{ps+\ceil{\log_2(n)}}{s}
\]
where \(s\) be the number of bits used by an uncompressed value, \(p\) be the percent of values that are compressed and \(n\) be the number of curves available.

\input{figures/2.Background/Compression/SZ-modes.tex}

The curves available are selected based on the nature of the data being compressed.
Note that the word curve is used loosely here to refer to any predictive function.
Figure~\ref{fig:comp-sz-modes} shows all of the curve fitting function that were used.
For compressing vector values, the Neighbor, Linear and Quadratic curves were used.
Because the vector values represent a value at each grid point, these curves attempted to capture smooth changes and relations in the data.
The matrix indices were compressed using only the increment compression mode, since approximately two thirds of the indices fit that pattern.
The matrix values were compressed with a few different combinations of curves.
These combinations were Neighbor alone, Neighbor and Neighbor's Neighbor, and Neighbor, Neighbor's Neighbor and Last Uncompressed.
These curves were chosen to find the best way to compress a series of -1's broken up by 26's.

\subsubsection{ZFP Compression}
%TODO ZFP compression

\subsubsection{Elias Gamma Coding and Delta Coding}
%TODO gamma and delta codings

\subsubsection{Op-Code Compression}
%TODO opcode compression

\subsubsection{Huffman Coding}
%TODO huffman coding

\subsubsection{Combined Compression Strategies}
%TODO combined compression

